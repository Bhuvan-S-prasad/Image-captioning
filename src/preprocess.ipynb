{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\bhuva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: image\n",
      "- caption\n",
      "--------------------\n",
      "Image: 1000268201_693b08cb0e.jpg\n",
      "- A child in a pink dress is climbing up a set of stairs in an entry way .\n",
      "- A girl going into a wooden building .\n",
      "- A little girl climbing into a wooden playhouse .\n",
      "- A little girl climbing the stairs to her playhouse .\n",
      "- A little girl in a pink dress going into a wooden cabin .\n",
      "--------------------\n",
      "Image: 1001773457_577c3a7d70.jpg\n",
      "- A black dog and a spotted dog are fighting\n",
      "- A black dog and a tri-colored dog playing with each other on the road .\n",
      "- A black dog and a white dog with brown spots are staring at each other in the street .\n",
      "- Two dogs of different breeds looking at each other on the road .\n",
      "- Two dogs on pavement moving toward each other .\n",
      "--------------------\n",
      "Image: 1002674143_1b742ab4b8.jpg\n",
      "- A little girl covered in paint sits in front of a painted rainbow with her hands in a bowl .\n",
      "- A little girl is sitting in front of a large painted rainbow .\n",
      "- A small girl in the grass plays with fingerpaints in front of a white canvas with a rainbow on it .\n",
      "- There is a girl with pigtails sitting in front of a rainbow painting .\n",
      "- Young girl with pigtails painting outside in the grass .\n",
      "--------------------\n",
      "Image: 1003163366_44323f5815.jpg\n",
      "- A man lays on a bench while his dog sits by him .\n",
      "- A man lays on the bench to which a white dog is also tied .\n",
      "- a man sleeping on a bench outside with a white and black dog sitting next to him .\n",
      "- A shirtless man lies on a park bench with his dog .\n",
      "- man laying on bench holding leash of dog sitting on ground\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_captions(captions_file_path):\n",
    "    \"\"\"\n",
    "    Loads and parses the captions from the captions.txt file.\n",
    "\n",
    "    Args:\n",
    "        captions_file_path (str): Path to the captions.txt file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are image filenames and values are lists of captions.\n",
    "    \"\"\"\n",
    "    caption_mapping = {}\n",
    "    with open(captions_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # Skip empty lines\n",
    "                continue\n",
    "            image_filename, caption = line.split(',', 1) # Split at the first comma\n",
    "            image_filename = image_filename.strip() # clean up filenames\n",
    "            caption = caption.strip() # clean up caption\n",
    "\n",
    "            if image_filename not in caption_mapping:\n",
    "                caption_mapping[image_filename] = []\n",
    "            caption_mapping[image_filename].append(caption)\n",
    "    return caption_mapping\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    captions_file = r\"C:\\Users\\bhuva\\Desktop\\image_captioning\\data\\raw\\flickr8k\\captions.txt\" # Assuming 'Flickr8k.token.txt' is the captions file name\n",
    "    if not os.path.exists(captions_file):\n",
    "        print(f\"Error: Captions file not found at {captions_file}. Please check the dataset download.\")\n",
    "    else:\n",
    "        caption_data = load_captions(captions_file)\n",
    "        # Let's print a few examples to check\n",
    "        example_filenames = list(caption_data.keys())[:5] # Get the first 5 image filenames\n",
    "        for filename in example_filenames:\n",
    "            print(f\"Image: {filename}\")\n",
    "            for caption in caption_data[filename]:\n",
    "                print(f\"- {caption}\")\n",
    "            print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: image\n",
      "- Tokens: ['caption']\n",
      "--------------------\n",
      "Image: 1000268201_693b08cb0e.jpg\n",
      "- Tokens: ['a', 'child', 'in', 'a', 'pink', 'dress', 'is', 'climbing', 'up', 'a', 'set', 'of', 'stairs', 'in', 'an', 'entry', 'way']\n",
      "- Tokens: ['a', 'girl', 'going', 'into', 'a', 'wooden', 'building']\n",
      "- Tokens: ['a', 'little', 'girl', 'climbing', 'into', 'a', 'wooden', 'playhouse']\n",
      "- Tokens: ['a', 'little', 'girl', 'climbing', 'the', 'stairs', 'to', 'her', 'playhouse']\n",
      "- Tokens: ['a', 'little', 'girl', 'in', 'a', 'pink', 'dress', 'going', 'into', 'a', 'wooden', 'cabin']\n",
      "--------------------\n",
      "Image: 1001773457_577c3a7d70.jpg\n",
      "- Tokens: ['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'are', 'fighting']\n",
      "- Tokens: ['a', 'black', 'dog', 'and', 'a', 'tricolored', 'dog', 'playing', 'with', 'each', 'other', 'on', 'the', 'road']\n",
      "- Tokens: ['a', 'black', 'dog', 'and', 'a', 'white', 'dog', 'with', 'brown', 'spots', 'are', 'staring', 'at', 'each', 'other', 'in', 'the', 'street']\n",
      "- Tokens: ['two', 'dogs', 'of', 'different', 'breeds', 'looking', 'at', 'each', 'other', 'on', 'the', 'road']\n",
      "- Tokens: ['two', 'dogs', 'on', 'pavement', 'moving', 'toward', 'each', 'other']\n",
      "--------------------\n",
      "Preprocessing caption data...\n",
      "Saving preprocessed caption data to: C:\\Users\\bhuva\\Desktop\\image_captioning\\outputs\\preprocessed_captions.pkl\n",
      "Preprocessed data saved.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk # You might need to install nltk: pip install nltk\n",
    "from nltk.tokenize import word_tokenize # If needed: nltk.download('punkt')\n",
    "import pickle\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by lowercasing and removing punctuation.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text caption.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned text.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation using regex (keep alphanumeric and whitespace)\n",
    "    return text\n",
    "\n",
    "def tokenize_caption(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the cleaned text into words.\n",
    "\n",
    "    Args:\n",
    "        text (str): Cleaned text caption.\n",
    "\n",
    "    Returns:\n",
    "        list: List of words (tokens).\n",
    "    \"\"\"\n",
    "    # Using nltk.word_tokenize for more robust tokenization (handles contractions, etc.)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def preprocess_captions(caption_mapping):\n",
    "    \"\"\"\n",
    "    Preprocesses all captions in the caption mapping.\n",
    "\n",
    "    Args:\n",
    "        caption_mapping (dict): Dictionary of image filenames to lists of captions.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with preprocessed captions (lists of tokens).\n",
    "    \"\"\"\n",
    "    preprocessed_caption_mapping = {}\n",
    "    for image_filename, captions in caption_mapping.items():\n",
    "        preprocessed_captions = []\n",
    "        for caption in captions:\n",
    "            cleaned_caption = clean_text(caption)\n",
    "            tokens = tokenize_caption(cleaned_caption)\n",
    "            preprocessed_captions.append(tokens)\n",
    "        preprocessed_caption_mapping[image_filename] = preprocessed_captions\n",
    "    return preprocessed_caption_mapping\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ... (Previous code to load captions) ...\n",
    "\n",
    "    if os.path.exists(captions_file):\n",
    "        caption_data = load_captions(captions_file)\n",
    "        preprocessed_data_file = r\"C:\\Users\\bhuva\\Desktop\\image_captioning\\outputs\\preprocessed_captions.pkl\"\n",
    "        preprocessed_caption_data = preprocess_captions(caption_data)\n",
    "\n",
    "\n",
    "        # Print a few examples of preprocessed captions\n",
    "        example_filenames = list(preprocessed_caption_data.keys())[:3]\n",
    "        for filename in example_filenames:\n",
    "            print(f\"Image: {filename}\")\n",
    "            for tokens in preprocessed_caption_data[filename]:\n",
    "                print(f\"- Tokens: {tokens}\")\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "    if os.path.exists(preprocessed_data_file):\n",
    "        print(f\"Loading preprocessed caption data from: {preprocessed_data_file}\")\n",
    "        with open(preprocessed_data_file, 'rb') as f: # 'rb' mode for reading binary file\n",
    "            preprocessed_caption_data = pickle.load(f)\n",
    "        print(\"Preprocessed data loaded successfully.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Preprocessing caption data...\")\n",
    "        if not os.path.exists(captions_file):\n",
    "            print(f\"Error: Captions file not found at {captions_file}. Please check the dataset download.\")\n",
    "        else:\n",
    "            caption_data = load_captions(captions_file)\n",
    "            preprocessed_caption_data = preprocess_captions(caption_data)\n",
    "\n",
    "            print(f\"Saving preprocessed caption data to: {preprocessed_data_file}\")\n",
    "            with open(preprocessed_data_file, 'wb') as f: # 'wb' mode for writing binary file\n",
    "                pickle.dump(preprocessed_caption_data, f) # Save the dictionary\n",
    "            print(\"Preprocessed data saved.\")\n",
    "\n",
    "    \n",
    "        # ... (Rest of your previous code, like caption length analysis, can be adapted if needed for preprocessed tokens) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocabulary...\n",
      "Vocabulary size: 2995\n",
      "Converting captions to indices and padding...\n",
      "Captions indexed and padded.\n",
      "\n",
      "Image: image\n",
      "- Indices: [1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Image: 1000268201_693b08cb0e.jpg\n",
      "- Indices: [1, 4, 5, 6, 4, 7, 8, 9, 10, 11, 4, 12, 13, 14, 6, 15, 3, 16, 2, 0]\n",
      "- Indices: [1, 4, 17, 18, 19, 4, 20, 21, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 22, 17, 10, 19, 4, 20, 23, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 22, 17, 10, 24, 14, 25, 26, 23, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 22, 17, 6, 4, 7, 8, 18, 19, 4, 20, 3, 2, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Image: 1001773457_577c3a7d70.jpg\n",
      "- Indices: [1, 4, 27, 28, 29, 4, 30, 28, 31, 32, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 27, 28, 29, 4, 33, 28, 34, 35, 36, 37, 38, 24, 39, 2, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 27, 28, 29, 4, 40, 28, 35, 41, 42, 31, 43, 44, 36, 37, 6, 24, 45, 2]\n",
      "- Indices: [1, 46, 47, 13, 48, 49, 50, 44, 36, 37, 38, 24, 39, 2, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 46, 47, 38, 51, 52, 53, 36, 37, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Saving processed data (vocabulary and indexed captions) to: C:\\Users\\bhuva\\Desktop\\image_captioning\\outputs\\preprocessed_captions.pkl\n",
      "Processed data saved.\n"
     ]
    }
   ],
   "source": [
    "# ... (rest of your previous imports and functions: load_captions, clean_text, tokenize_caption, preprocess_captions) ...\n",
    "\n",
    "# Special tokens\n",
    "PAD_TOKEN = '<pad>'\n",
    "START_TOKEN = '<start>'\n",
    "END_TOKEN = '<end>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "SPECIAL_TOKENS = [PAD_TOKEN, START_TOKEN, END_TOKEN, UNK_TOKEN]\n",
    "\n",
    "def create_vocabulary(preprocessed_caption_data, vocab_threshold=5):\n",
    "    \"\"\"\n",
    "    Creates a vocabulary from the preprocessed captions.\n",
    "\n",
    "    Args:\n",
    "        preprocessed_caption_data (dict): Dictionary of image filenames to lists of tokenized captions.\n",
    "        vocab_threshold (int): Minimum word frequency threshold to be included in the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        dict: word_to_index dictionary (vocabulary).\n",
    "    \"\"\"\n",
    "    word_counts = {}\n",
    "    for captions_list in preprocessed_caption_data.values():\n",
    "        for tokens in captions_list:\n",
    "            for token in tokens:\n",
    "                word_counts[token] = word_counts.get(token, 0) + 1\n",
    "\n",
    "    # Filter words based on threshold and create vocabulary\n",
    "    vocab = {PAD_TOKEN: 0, START_TOKEN: 1, END_TOKEN: 2, UNK_TOKEN: 3} # Start with special tokens\n",
    "    next_index = len(SPECIAL_TOKENS)\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= vocab_threshold:\n",
    "            vocab[word] = next_index\n",
    "            next_index += 1\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def captions_to_indices(preprocessed_caption_data, vocab, max_length=20): # Setting a default max_length for now\n",
    "    \"\"\"\n",
    "    Converts tokenized captions to sequences of numerical indices and pads them.\n",
    "\n",
    "    Args:\n",
    "        preprocessed_caption_data (dict): Dictionary of image filenames to lists of tokenized captions.\n",
    "        vocab (dict): word_to_index vocabulary.\n",
    "        max_length (int): Maximum caption length for padding.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of image filenames to lists of numericalized and padded caption sequences.\n",
    "    \"\"\"\n",
    "    indexed_caption_mapping = {}\n",
    "    for image_filename, captions_list in preprocessed_caption_data.items():\n",
    "        indexed_captions = []\n",
    "        for tokens in captions_list:\n",
    "            indexed_tokens = [vocab.get(token, vocab[UNK_TOKEN]) for token in tokens] # Use UNK for unknown words\n",
    "            indexed_tokens = [vocab[START_TOKEN]] + indexed_tokens + [vocab[END_TOKEN]] # Add start and end tokens\n",
    "\n",
    "            # Padding or Truncating\n",
    "            if len(indexed_tokens) > max_length:\n",
    "                indexed_tokens = indexed_tokens[:max_length] # Truncate if longer than max_length\n",
    "            else:\n",
    "                indexed_tokens = indexed_tokens + [vocab[PAD_TOKEN]] * (max_length - len(indexed_tokens)) # Pad if shorter\n",
    "\n",
    "            indexed_captions.append(indexed_tokens)\n",
    "        indexed_caption_mapping[image_filename] = indexed_captions\n",
    "    return indexed_caption_mapping\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ... (rest of your __main__ block - loading preprocessed data from pickle) ...\n",
    "\n",
    "    if os.path.exists(preprocessed_data_file):\n",
    "        with open(preprocessed_data_file, 'rb') as f:\n",
    "            preprocessed_caption_data = pickle.load(f)\n",
    "\n",
    "        print(\"Creating vocabulary...\")\n",
    "        vocabulary = create_vocabulary(preprocessed_caption_data)\n",
    "        print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "\n",
    "        print(\"Converting captions to indices and padding...\")\n",
    "        indexed_caption_data = captions_to_indices(preprocessed_caption_data, vocabulary)\n",
    "        print(\"Captions indexed and padded.\")\n",
    "\n",
    "        # Example of indexed captions\n",
    "        example_filenames = list(indexed_caption_data.keys())[:3]\n",
    "        for filename in example_filenames:\n",
    "            print(f\"\\nImage: {filename}\")\n",
    "            for indexed_tokens in indexed_caption_data[filename]:\n",
    "                print(f\"- Indices: {indexed_tokens}\")\n",
    "\n",
    "        # Save vocabulary and indexed data (optional, but good practice - you can save vocab to a separate file too)\n",
    "        processed_data_output_file = r\"C:\\Users\\bhuva\\Desktop\\image_captioning\\outputs\\preprocessed_captions.pkl\"\n",
    "        print(f\"\\nSaving processed data (vocabulary and indexed captions) to: {processed_data_output_file}\")\n",
    "        data_to_save = {'vocab': vocabulary, 'indexed_captions': indexed_caption_data}\n",
    "        with open(processed_data_output_file, 'wb') as f:\n",
    "            pickle.dump(data_to_save, f)\n",
    "        print(\"Processed data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Vocabulary size: 2995\n",
      "\n",
      "Image: image\n",
      "- Indices: [1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Image: 1000268201_693b08cb0e.jpg\n",
      "- Indices: [1, 4, 5, 6, 4, 7, 8, 9, 10, 11, 4, 12, 13, 14, 6, 15, 3, 16, 2, 0]\n",
      "- Indices: [1, 4, 17, 18, 19, 4, 20, 21, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 22, 17, 10, 19, 4, 20, 23, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 22, 17, 10, 24, 14, 25, 26, 23, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 22, 17, 6, 4, 7, 8, 18, 19, 4, 20, 3, 2, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Image: 1001773457_577c3a7d70.jpg\n",
      "- Indices: [1, 4, 27, 28, 29, 4, 30, 28, 31, 32, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 27, 28, 29, 4, 33, 28, 34, 35, 36, 37, 38, 24, 39, 2, 0, 0, 0, 0]\n",
      "- Indices: [1, 4, 27, 28, 29, 4, 40, 28, 35, 41, 42, 31, 43, 44, 36, 37, 6, 24, 45, 2]\n",
      "- Indices: [1, 46, 47, 13, 48, 49, 50, 44, 36, 37, 38, 24, 39, 2, 0, 0, 0, 0, 0, 0]\n",
      "- Indices: [1, 46, 47, 38, 51, 52, 53, 36, 37, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "processed_data_file = r\"C:\\Users\\bhuva\\Desktop\\image_captioning\\outputs\\preprocessed_captions.pkl\" # Path to your saved file\n",
    "\n",
    "if os.path.exists(processed_data_file):\n",
    "    with open(processed_data_file, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "\n",
    "    vocabulary = loaded_data['vocab']\n",
    "    indexed_captions = loaded_data['indexed_captions']\n",
    "\n",
    "    print(f\"Loaded Vocabulary size: {len(vocabulary)}\")\n",
    "    example_filenames = list(indexed_captions.keys())[:3]\n",
    "    for filename in example_filenames:\n",
    "        print(f\"\\nImage: {filename}\")\n",
    "        for indexed_tokens in indexed_captions[filename]:\n",
    "            print(f\"- Indices: {indexed_tokens}\")\n",
    "else:\n",
    "    print(f\"Error: {processed_data_file} not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
